{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8YRSZ6kK3Qer",
    "outputId": "cfe3b3f9-fbf9-42bb-b773-af55b532fe20"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/Users/vamshi/Documents/spark-3.0.0-preview2-bin-hadoop2.7')\n",
    "# findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\")\\\n",
    "        .config(\"spark.executor.memory\", \"16g\")\\\n",
    "        .config(\"spark.driver.memory\", \"16g\")\\\n",
    "        .config(\"spark.memory.offHeap.enabled\",'true')\\\n",
    "        .config(\"spark.memory.offHeap.size\",\"16g\")\\\n",
    "        .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoHi4QdC5apa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval \n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76Y4Nnuc6OK5"
   },
   "outputs": [],
   "source": [
    "train_pd_data_frame = pd.read_csv(r'train.csv')\n",
    "train_spark_data_frame = spark.createDataFrame(train_pd_data_frame)\n",
    "train_pd_data_frame['genre']= train_pd_data_frame['genre'].apply(literal_eval)\n",
    "s = train_pd_data_frame['genre'].to_list()\n",
    "\n",
    "mapping_df = pd.read_csv(\"mapping.csv\")\n",
    "mapping_spark_df = spark.createDataFrame(mapping_df)\n",
    "\n",
    "genres = []\n",
    "\n",
    "for i in range(mapping_spark_df.count()):\n",
    "    genres.append(mapping_spark_df.take(20)[i][1])\n",
    "\n",
    "matrix = np.zeros((len(train_pd_data_frame),len(genres)))\n",
    "for i,genre in enumerate(s):\n",
    "    for j,g in enumerate(genre):\n",
    "        for k,name in enumerate(genres):\n",
    "            if name==g:\n",
    "                matrix[i][k] = 1\n",
    "genre_csv = str(genres).replace(\"[\",\"\").replace(\"]\",\"\").strip().replace(\"'\", \"\")\n",
    "\n",
    "np.savetxt(\"genres.csv\", matrix, delimiter=\",\",fmt='%d',header=genre_csv, comments='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wMajSknMC3W"
   },
   "outputs": [],
   "source": [
    "labels_data_frame = pd.read_csv(r'genres.csv')\n",
    "test_pd_data_frame = pd.read_csv(r'test.csv')\n",
    "labels_spark_df = spark.createDataFrame(labels_data_frame)\n",
    "test_spark_data_frame = spark.createDataFrame(test_pd_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZUNn84K21fS"
   },
   "outputs": [],
   "source": [
    "dataframe1 = train_spark_data_frame.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "dataframe2 = labels_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "dataframe3 = test_spark_data_frame.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "final_dataframe = dataframe1.join(dataframe2, \"row_id\").drop(\"row_id\")\n",
    "test_df = dataframe3.join(dataframe2, \"row_id\").drop(\"row_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z593o_L88AEK",
    "outputId": "6a3870e3-a024-4aef-cee9-190937b2be33"
   },
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, hashingTF])\n",
    "\n",
    "model = pipeline.fit(final_dataframe)\n",
    "train_dataset = model.transform(final_dataframe)\n",
    "\n",
    "model2 = pipeline.fit(test_df)\n",
    "test_dataset = model2.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bI_skgB9HaAT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfList = []\n",
    "labelCols = labels_spark_df.columns\n",
    "lr = LogisticRegression(featuresCol = 'features',maxIter=50)\n",
    "for labelCol in labelCols:\n",
    "\n",
    "    lr.setLabelCol(labelCol)\n",
    "    lrModel = lr.fit(train_dataset)\n",
    "    predictions = lrModel.transform(test_dataset)\n",
    "    predictions = predictions.withColumn(\"prediction\",F.col(\"prediction\").cast(IntegerType()))\n",
    "    dfList.append(predictions.select(\"movie_id\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m2q85P2sqBl"
   },
   "outputs": [],
   "source": [
    "dfs_renamed = [df.selectExpr('movie_id', f'prediction as prediction_{i}') for i, df in enumerate(dfList)]\n",
    "temp_df = reduce(lambda x, y: x.join(y, ['movie_id'], how='full'), dfs_renamed)\n",
    "col_list = ['prediction_%d' % i for i in range(len(dfList))]\n",
    "temp_df = temp_df.withColumn('predictions',concat_ws(\" \",*col_list)).drop(*col_list).toPandas().to_csv(\"part1_finalPredictions.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"features\", outputCol=\"idf_features\")\n",
    "idfModel = idf.fit(train_dataset)\n",
    "rescaledTrainData = idfModel.transform(train_dataset)\n",
    "rescaledTestData = idfModel.transform(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = []\n",
    "labelCols = labels_spark_df.columns\n",
    "lr = LogisticRegression(featuresCol = 'idf_features',maxIter=50)\n",
    "for labelCol in labelCols:\n",
    "    lr.setLabelCol(labelCol)\n",
    "    lrModel = lr.fit(rescaledTrainData)\n",
    "    predictions = lrModel.transform(rescaledTestData)\n",
    "    predictions = predictions.withColumn(\"prediction\",F.col(\"prediction\").cast(IntegerType()))\n",
    "    dfList.append(predictions.select(\"movie_id\",\"prediction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_renamed = [df.selectExpr('movie_id', f'prediction as prediction_{i}') for i, df in enumerate(dfList)]\n",
    "temp_df = reduce(lambda x, y: x.join(y, ['movie_id'], how='full'), dfs_renamed)\n",
    "col_list = ['prediction_%d' % i for i in range(len(dfList))]\n",
    "temp_df = temp_df.withColumn('predictions',concat_ws(\" \",*col_list)).drop(*col_list).toPandas().to_csv(\"tf-idf_predictions.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=300, minCount=0, inputCol=\"words\", outputCol=\"w2v_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_model = word2Vec.fit(train_dataset)\n",
    "\n",
    "W2V_train_data = W2V_model.transform(train_dataset)\n",
    "W2V_test_data = W2V_model.transform(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = []\n",
    "labelCols = labels_spark_df.columns\n",
    "lr = LogisticRegression(featuresCol = 'w2v_features',maxIter=1000)\n",
    "for labelCol in labelCols:\n",
    "    lr.setLabelCol(labelCol)\n",
    "    lrModel = lr.fit(W2V_train_data)\n",
    "    predictions = lrModel.transform(W2V_test_data)\n",
    "    predictions = predictions.withColumn(\"prediction\",F.col(\"prediction\").cast(IntegerType()))\n",
    "    dfList.append(predictions.select(\"movie_id\",\"prediction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_renamed = [df.selectExpr('movie_id', f'prediction as prediction_{i}') for i, df in enumerate(dfList)]\n",
    "temp_df = reduce(lambda x, y: x.join(y, ['movie_id'], how='full'), dfs_renamed)\n",
    "col_list = ['prediction_%d' % i for i in range(len(dfList))]\n",
    "temp_df = temp_df.withColumn('predictions',concat_ws(\" \",*col_list)).drop(*col_list).toPandas().to_csv(\"word2vec_predictions.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DIC_PySpark_Part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
